{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(color_codes=True)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_train = pd.read_csv('C:/Users/welcome/Downloads/GL_Hackathon/frequency_domain_features_train.csv')\n",
    "fd_test = pd.read_csv('C:/Users/welcome/Downloads/GL_Hackathon/frequency_domain_features_test.csv')\n",
    "td_train = pd.read_csv('C:/Users/welcome/Downloads/GL_Hackathon/time_domain_features_train.csv')\n",
    "td_test = pd.read_csv('C:/Users/welcome/Downloads/GL_Hackathon/time_domain_features_test.csv')\n",
    "hr_train = pd.read_csv('C:/Users/welcome/Downloads/GL_Hackathon/heart_rate_non_linear_features_train.csv')\n",
    "hr_test = pd.read_csv('C:/Users/welcome/Downloads/GL_Hackathon/heart_rate_non_linear_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(fd_train, td_train, how='outer', on='uuid')\n",
    "df_train = pd.merge(df3, hr_train, how='outer', on='uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(fd_test, td_test, how='outer', on='uuid')\n",
    "df_test = pd.merge(df2, hr_test, how='outer', on='uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop('HR')\n",
    "X_train = df_train.copy(deep = True)\n",
    "X_test = df_test.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns= ['datasetId'], inplace=True)\n",
    "X_test.drop(columns= ['datasetId'], inplace=True)\n",
    "X_train.drop(columns= ['uuid'], inplace=True)\n",
    "y_id = X_test.pop('uuid')\n",
    "X_train.drop(columns= ['SKEW_REL_RR','KURT_REL_RR'], inplace=True)\n",
    "X_test.drop(columns= ['SKEW_REL_RR','KURT_REL_RR'], inplace=True)\n",
    "X_train.drop(columns= ['SDSD_REL_RR'], inplace=True) \n",
    "X_test.drop(columns= ['SDSD_REL_RR'], inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['VLF', 'VLF_PCT', 'LF', 'LF_PCT', 'LF_NU', 'HF', 'HF_PCT', 'HF_NU',\n",
    "       'TP', 'LF_HF', 'HF_LF', 'MEAN_RR', 'MEDIAN_RR', 'SDRR', 'RMSSD', 'SDSD',\n",
    "       'SDRR_RMSSD', 'pNN25', 'pNN50', 'KURT', 'SKEW', 'MEAN_REL_RR',\n",
    "       'MEDIAN_REL_RR', 'SDRR_REL_RR', 'RMSSD_REL_RR', 'SDRR_RMSSD_REL_RR',\n",
    "       'SD1', 'SD2', 'sampen', 'higuci']\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso()\n",
    "\n",
    "model.fit(X_train[cols], y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col2 = pd.DataFrame(model.coef_ * 10000,np.array(cols))\n",
    "col2.columns = ['val']\n",
    "\n",
    "final_cols = col2[col2['val']!=0].index\n",
    "\n",
    "X_train = X_train[final_cols]\n",
    "X_test = X_test[final_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['condition'] = hr_train['condition']\n",
    "X_test['condition'] = hr_test['condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = X_train.describe(include = ['O']).columns\n",
    "numerical_columns = X_train.describe().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.size, X_test.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns.size +  numerical_columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pl_n = Pipeline([\n",
    "                #  ('imputerNaN', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "                #  ('imputer0', SimpleImputer(missing_values=0, strategy='median')),\n",
    "                 ('std', StandardScaler()),\n",
    "                 ('power', PowerTransformer())\n",
    "])\n",
    "\n",
    "pl_c = Pipeline([\n",
    "                #  ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "                 ('std', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "                        ('num', pl_n, numerical_columns),\n",
    "                        ('cat', pl_c, categorical_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.00002871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "model = Pipeline([\n",
    "               ('ct', ct),\n",
    "               ('lr', ExtraTreesRegressor(n_estimators=500, random_state=1, n_jobs=-1))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict = model.predict(X_test)\n",
    "y_train_predict = model.predict(X_train)\n",
    "\n",
    "\n",
    "print('Training Score: ', '%0.8f'%mean_absolute_error(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64.70946452, 73.77736252, 69.19811525, ..., 60.94928377,\n",
       "       77.40858181, 76.59910561])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame(y_id),pd.DataFrame(y_test_predict)], axis=1, ignore_index=True)\n",
    "df.columns = ['uuid','HR']\n",
    "df.to_csv('C:/Users/welcome/Downloads/GL_Hackathon/ETR500Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
