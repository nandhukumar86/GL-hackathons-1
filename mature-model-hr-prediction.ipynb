{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import sidetable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(\"heart-rate-final.csv\") #--> this is the merged file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the training data\n",
    "df_train = df_final.copy()\n",
    "\n",
    "uuid = df_train.pop('uuid') #Extract the UUID, we are simply dropping the column here\n",
    "\n",
    "y_train = df_train.pop('HR') #Heart rate is the target variable\n",
    "\n",
    "#Drop datasetId column\n",
    "df_train = df_train.drop(['datasetId'], axis=1)\n",
    "\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the test dataset\n",
    "df_final_test = pd.read_csv(\"heart-rate-final-test.csv\") #--> this is the merged file\n",
    "df_final_test = df_final_test.drop(df_final_test.columns[0], axis=1)\n",
    "\n",
    "df_test = df_final_test.copy()\n",
    "\n",
    "test_uuid = df_test.pop('uuid') #Extract the UUID\n",
    "\n",
    "#Drop datasetId column\n",
    "df_test = df_test.drop(['datasetId'], axis=1)\n",
    "\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin the pipelining!\n",
    "categorical_columns = ['condition']\n",
    "numerical_columns = X_train.describe().columns\n",
    "\n",
    "\n",
    "pipeline_numerical = Pipeline([('scaler', StandardScaler()),('power', PowerTransformer())])\n",
    "\n",
    "pipeline_categorical = Pipeline([('onehot', OneHotEncoder())])\n",
    "\n",
    "t = [('cat', pipeline_categorical, categorical_columns), ('num', pipeline_numerical, numerical_columns)]\n",
    "ct = ColumnTransformer(transformers=t, remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Fit the model!\n",
    "model = Pipeline([('ct', ct),('lr', ExtraTreesRegressor())])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.00000000\n"
     ]
    }
   ],
   "source": [
    "y_test_predict = model.predict(X_test)\n",
    "y_train_predict = model.predict(X_train)\n",
    "\n",
    "print('MAE: ', '%0.8f'%mean_absolute_error(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64.709432 73.777723 69.19798  ... 60.942905 77.409522 76.607111]\n"
     ]
    }
   ],
   "source": [
    "#Generating the predictions and preparing the submission file!\n",
    "y_test_predict = y_test_predict.round(6) ##Rounding to the 6th digit since the HR was to the 6th digit in the original data\n",
    "\n",
    "print(y_test_predict)\n",
    "\n",
    "predicted_frame = pd.concat([pd.DataFrame(test_uuid), pd.DataFrame(y_test_predict)], axis =1, ignore_index = True)\n",
    "\n",
    "predicted_frame.columns = ['uuid','HR']\n",
    "\n",
    "predicted_frame.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameter tuning\n",
    "param_grid={\n",
    "    'lr__n_estimators': [100,200,300]\n",
    "}\n",
    "grid = GridSearchCV(model, param_grid=param_grid,scoring='neg_mean_absolute_error', cv=2, refit=True)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_predict = grid.predict(X_test)\n",
    "\n",
    "hr_predict = hr_predict.round(6)\n",
    "\n",
    "hr_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
